{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b38bda87-b048-4bb6-900e-11b4359b2c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "# Load the data set\n",
    "cancer = load_breast_cancer()\n",
    "\n",
    "# Split into training and testing data\n",
    "X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target, random_state=19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c32b331e-c25f-474b-9b8b-bba6680bea16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'deprecated', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'liblinear', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(solver='liblinear', max_iter=1000)\n",
    "\n",
    "print(lr.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10075146-2872-4efd-968f-30fe10626e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'penalty':['l1', 'l2'],\n",
    "    'C':[1, 10, 100]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "838b9957-6cbf-40b3-9301-4f6df6bb96aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cv': None, 'error_score': nan, 'estimator__C': 1.0, 'estimator__class_weight': None, 'estimator__dual': False, 'estimator__fit_intercept': True, 'estimator__intercept_scaling': 1, 'estimator__l1_ratio': None, 'estimator__max_iter': 1000, 'estimator__multi_class': 'deprecated', 'estimator__n_jobs': None, 'estimator__penalty': 'l2', 'estimator__random_state': None, 'estimator__solver': 'liblinear', 'estimator__tol': 0.0001, 'estimator__verbose': 0, 'estimator__warm_start': False, 'estimator': LogisticRegression(max_iter=1000, solver='liblinear'), 'n_jobs': None, 'param_grid': {'penalty': ['l1', 'l2'], 'C': [1, 10, 100]}, 'pre_dispatch': '2*n_jobs', 'refit': True, 'return_train_score': False, 'scoring': None, 'verbose': 0}\n"
     ]
    }
   ],
   "source": [
    "clf = GridSearchCV(estimator=lr, param_grid=parameters)\n",
    "\n",
    "print(clf.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78275173-05a3-45a4-96d3-a8b85da0ebb9",
   "metadata": {},
   "source": [
    "The “CV” in GridSearchCV is an acronym for cross-validation. It’s best practice in \n",
    "Preview: Docs Machine learning is a branch of artificial intelligence that enables systems to learn from data and make predictions or decisions without explicit programming.\n",
    "machine learning to go beyond the usual train-test split and have a holdout or validation dataset. Specifically, GridSearhCV uses a technique known as k-fold cross-validation. This works as follows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ebaab8-710d-4d3c-927a-fdf86628ccad",
   "metadata": {},
   "source": [
    "## Cross-validation in GridSearchCV\n",
    "GridSearchCV subdivides the training data further into another training and test data set. It fits the model on this new training data and evaluates the model on the new test data. But to make sure that we don’t accidentally have good performance in only one part of our dataset, GridSearchCV will do this process multiple times on different cross-validation splits so that every point in the data gets to be tested on at least once! The number of times this split happens is the “k” in “k-fold”. For instance, in a 10-fold cross-validation, our data would be split into a 90:10 train-test split 10 times and GridSearchCV would evaluate the model on each fold."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787d639d-de54-4550-b9ab-dbd4e174c69f",
   "metadata": {},
   "source": [
    "Evaluating GridSearchCV results\n",
    "After fitting a GridSearchCV model we can find out the results using the following attributes of the clf argument:\n",
    "\n",
    "- .best_estimator_ gives us the best estimator\n",
    "- .best_score_ gives us the mean cross-validated score corresponding to the best estimator\n",
    "- .best_params_ gives us the set of hyperparameters that correspond to the best estimator\n",
    "Additionally, the .cv_results_ attribute gives us the scores for each hyperparamter combination in the grid. We’re now ready to evaluate the grid search we set up earlier and we’ve preloaded the code from the previous exercise in the Setup cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99765bc2-56c5-4212-bd7a-439ff5d345b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=10, max_iter=1000, penalty='l1', solver='liblinear')\n",
      "{'C': 10, 'penalty': 'l1'}\n"
     ]
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)\n",
    "best_model = clf.best_estimator_\n",
    "\n",
    "\n",
    "print(best_model)\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37088af8-a31e-4e2a-bc56-62088a4f72d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Store the best score from the grid search\n",
    "best_score = clf.best_score_\n",
    "\n",
    "# Get the best estimator and evaluate on the test set\n",
    "best_model = clf.best_estimator_\n",
    "test_predictions = best_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "test_score = accuracy_score(y_test, test_predictions)\n",
    "\n",
    "\n",
    "print(best_score)\n",
    "print(test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e44cbc97-2385-4574-87d9-a20ccabcde98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     C penalty         0\n",
      "0    1      l1  0.957702\n",
      "1    1      l2  0.952996\n",
      "2   10      l1  0.967114\n",
      "3   10      l2  0.957702\n",
      "4  100      l1  0.955321\n",
      "5  100      l2  0.960027\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.957702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.952996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.967114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.957702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.955321</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0\n",
       "0  0.957702\n",
       "1  0.952996\n",
       "2  0.967114\n",
       "3  0.957702\n",
       "4  0.955321"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "hyperparameter_grid = pd.DataFrame(clf.cv_results_['params'])\n",
    "grid_scores = pd.DataFrame(clf.cv_results_['mean_test_score'])\n",
    "# grid_scores['score'] = grid_scores['0']\n",
    "\n",
    "df = pd.concat([hyperparameter_grid, grid_scores], axis = 1)\n",
    "print(df)\n",
    "grid_scores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03970ade-14fc-43b8-a7fc-010b488a852e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
